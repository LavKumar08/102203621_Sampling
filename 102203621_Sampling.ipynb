{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_KmCSRCH8DS",
        "outputId": "bd25b6c5-0073-4717-e2b8-9b46bb38fa15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Results:\n",
            "                                      10%       20%       30%       40%  \\\n",
            "Logistic Regression             0.935484  0.918033  0.869565  0.844262   \n",
            "Random Forest                   0.967742  0.983607  0.956522  1.000000   \n",
            "SVC (Linear)                    0.967742  0.885246  0.847826  0.868852   \n",
            "SVC (RBF)                       0.548387  0.721311  0.673913  0.655738   \n",
            "Random Forest (200 Estimators)  0.967742  0.983607  0.956522  0.991803   \n",
            "\n",
            "                                     50%  \n",
            "Logistic Regression             0.875817  \n",
            "Random Forest                   1.000000  \n",
            "SVC (Linear)                    0.921569  \n",
            "SVC (RBF)                       0.660131  \n",
            "Random Forest (200 Estimators)  1.000000  \n",
            "\n",
            "Best Model: 40%\n",
            "Best Sampling Technique: Random Forest\n",
            "Best Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('Creditcard_data.csv')\n",
        "\n",
        "def balance_data(X, y, technique=\"SMOTE\"):\n",
        "    if technique == \"SMOTE\":\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "    elif technique == \"undersampling\":\n",
        "        rus = RandomUnderSampler(random_state=42)\n",
        "        X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid balancing technique\")\n",
        "    return X_resampled, y_resampled\n",
        "\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Apply balancing technique\n",
        "X_balanced, y_balanced = balance_data(X, y)\n",
        "\n",
        "# Define sample sizes and sample data\n",
        "sample_sizes = [int(len(X_balanced) * 0.1 * i) for i in range(1, 6)]\n",
        "samples = [X_balanced.sample(n=size, random_state=42) for size in sample_sizes]\n",
        "sample_labels = [y_balanced.iloc[sample.index] for sample in samples]\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVC (Linear)\": SVC(kernel=\"linear\"),\n",
        "    \"SVC (RBF)\": SVC(kernel=\"rbf\"),\n",
        "    \"Random Forest (200 Estimators)\": RandomForestClassifier(n_estimators=200)\n",
        "}\n",
        "\n",
        "# Define results dictionary to store accuracies\n",
        "results = {}\n",
        "\n",
        "# Train models and record accuracies\n",
        "for i, (X_sample, y_sample) in enumerate(zip(samples, sample_labels)):\n",
        "    technique_name = f\"{(i + 1) * 10}%\"  # Use more descriptive names\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # Split data into train/test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict and calculate accuracy\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        if model_name not in results:\n",
        "            results[model_name] = {}\n",
        "        results[model_name][technique_name] = accuracy\n",
        "\n",
        "# Convert results dictionary into DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Accuracy Results:\\n\", results_df)\n",
        "\n",
        "# Find the model and technique with the highest accuracy\n",
        "best_model = results_df.max().idxmax()  # Get the column name of the highest accuracy\n",
        "best_technique = results_df[best_model].idxmax()  # Get the row name of the highest accuracy\n",
        "best_accuracy = results_df[best_model].max()  # Get the highest accuracy score\n",
        "\n",
        "print(f\"\\nBest Model: {best_model}\")\n",
        "print(f\"Best Sampling Technique: {best_technique}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n"
      ]
    }
  ]
}